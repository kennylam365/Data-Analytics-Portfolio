---
title: "Divvy Google DA Capstone"
author: "DA Cert"
date: "2023-01-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Cyclistic AY2019 Overview

This is a capstone project done by me for my google Data Analytics Project. The data used in this capstone project is from <https://divvy-tripdata.s3.amazonaws.com/index.html>. For this capstone, I am using the raw data for the period Q2 2019 - Q1 2020. Remember to set your working directory accordingly if there is any run error and download the 3 packages needed below, tidyverse, lubridate, and ggplot2.

### Uploading raw data

```{r uploading data}
library(tidyverse)
library(lubridate)
library(ggplot2)
q2_2019 <- read_csv("Divvy_Trips_2019_Q2.csv")
q3_2019 <- read_csv("Divvy_Trips_2019_Q3.csv")
q4_2019 <- read_csv("Divvy_Trips_2019_Q4.csv")
q1_2020 <- read_csv("Divvy_Trips_2020_Q1.csv")
```

### Wrangle and merging raw data

We need to merge the raw data before we begin our analysis. We start by renaming the columns to ensure that we can combine the raw data into a single file.

```{r rename}
colnames(q2_2019)
colnames(q3_2019)
colnames(q4_2019)
colnames(q1_2020)
(q2_2019 <- rename(q2_2019
                   ,ride_id = "01 - Rental Details Rental ID"
                   ,rideable_type = "01 - Rental Details Bike ID" 
                   ,started_at = "01 - Rental Details Local Start Time"  
                   ,ended_at = "01 - Rental Details Local End Time"  
                   ,start_station_name = "03 - Rental Start Station Name" 
                   ,start_station_id = "03 - Rental Start Station ID"
                   ,end_station_name = "02 - Rental End Station Name" 
                   ,end_station_id = "02 - Rental End Station ID"
                   ,member_casual = "User Type"))

(q3_2019 <- rename(q3_2019
                   ,ride_id = "01 - Rental Details Rental ID"
                   ,rideable_type = "01 - Rental Details Bike ID" 
                   ,started_at = "01 - Rental Details Local Start Time"  
                   ,ended_at = "01 - Rental Details Local End Time"  
                   ,start_station_name = "03 - Rental Start Station Name" 
                   ,start_station_id = "03 - Rental Start Station ID"
                   ,end_station_name = "02 - Rental End Station Name" 
                   ,end_station_id = "02 - Rental End Station ID"
                   ,member_casual = "User Type"))

(q4_2019 <- rename(q4_2019
                   ,ride_id = "01 - Rental Details Rental ID"
                   ,rideable_type = "01 - Rental Details Bike ID" 
                   ,started_at = "01 - Rental Details Local Start Time"  
                   ,ended_at = "01 - Rental Details Local End Time"  
                   ,start_station_name = "03 - Rental Start Station Name" 
                   ,start_station_id = "03 - Rental Start Station ID"
                   ,end_station_name = "02 - Rental End Station Name" 
                   ,end_station_id = "02 - Rental End Station ID"
                   ,member_casual = "User Type"))
```

### Inspect the dataframes and look for incongruencies

As the we are looking to combine the files together, we have to ensure that they are of the same data types so that they can stack correctly.

```{r inspect dataframes}
str(q2_2019)
str(q3_2019)
str(q4_2019)
str(q1_2020)
```

Convert ride_id and rideable_type to character so that they can stack correctly
```{r Convert ride_id and rideable_type to character}
q4_2019 <-  mutate(q4_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q3_2019 <-  mutate(q3_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q2_2019 <-  mutate(q2_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q1_2020 <-  mutate(q1_2020, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
```

### Combining the quarterly dataframes into a single yearly dataframe
```{r Cyclistic_Data}
Cyclistic_Data <- bind_rows(q2_2019, q3_2019, q4_2019, q1_2020)
colnames(Cyclistic_Data)
```

Remove lat, long, birthyear, and gender fields as this data was dropped beginning in 2020
```{r remove columns}
Cyclistic_Data <- Cyclistic_Data %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng, "01 - Rental Details Duration In Seconds Uncapped", "05 - Member Details Member Birthday Year", "Member Gender"))
```

Inspect the the new data table created
```{r inspect data table}
colnames(Cyclistic_Data)  #List of column names
nrow(Cyclistic_Data)  #How many rows are in data frame?
dim(Cyclistic_Data)  #Dimensions of the data frame?
head(Cyclistic_Data)  #See the first 6 rows of data frame.  Also tail(all_trips)
str(Cyclistic_Data)  #See list of columns and data types (numeric, character, etc)
summary(Cyclistic_Data)  #Statistical summary of data. Mainly for numerics
unique(Cyclistic_Data$member_casual)
```

### Clean up and add data for analysis
Some problems we have to address:

(1) In the "member_casual" column, there are two names for members ("member" and "Subscriber") and two names for casual riders ("Customer" and "casual"). We will need to consolidate that from four to two labels.

(2) The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.

(3) We will want to add a calculated field for length of ride since the 2020Q1 data did not have the "tripduration" column. We will add "ride_length" to the entire dataframe for consistency.

(4) There are some rides where tripduration shows up as negative, including several hundred rides where Divvy took bikes out of circulation for Quality Control reasons. We will want to delete these rides.

Before 2020, Divvy used different labels for these two types of riders ... we will want to make our dataframe consistent with their current nomenclature

```{r fix problem 1} 
Cyclistic_Data <-  Cyclistic_Data %>% 
  mutate(member_casual = recode(member_casual
                           ,"Subscriber" = "member"
                           ,"Customer" = "casual")) # Reassign to the current 2020 labels

table(Cyclistic_Data$member_casual) # Check to make sure the proper number of observations were reassigned
```

Add columns that list the date, month, day, and year of each ride
This will allow us to aggregate ride data for each month, day, or year, before completing these operations we could only aggregate at the ride level

```{r fix problem 2}
Cyclistic_Data$date <- as.Date(Cyclistic_Data$started_at) #The default format is yyyy-mm-dd
Cyclistic_Data$month <- format(as.Date(Cyclistic_Data$date), "%m")
Cyclistic_Data$day <- format(as.Date(Cyclistic_Data$date), "%d")
Cyclistic_Data$year <- format(as.Date(Cyclistic_Data$date), "%Y")
Cyclistic_Data$day_of_week <- format(as.Date(Cyclistic_Data$date), "%A")
```

Add a "ride_length" calculation to all_trips (in seconds)
```{r fix problem 3}
Cyclistic_Data$ride_length <- difftime(Cyclistic_Data$ended_at,Cyclistic_Data$started_at)
str(Cyclistic_Data) # Inspect the structure of the columns
is.factor(Cyclistic_Data$ride_length) # Convert "ride_length" from factor to numeric so we can run calculations on the data
Cyclistic_Data$ride_length <- as.numeric(as.character(Cyclistic_Data$ride_length))
is.numeric(Cyclistic_Data$ride_length) # Check to ensure that the data is numeric type)
```

Cleaning bad data
The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Cyclistic or ride_length was negative. We will create a new version of the dataframe (v2) since data is being removed
```{r removing bad data}
Cyclistic_Data_v2 <- Cyclistic_Data[!(Cyclistic_Data$start_station_name == "HQ QR" | Cyclistic_Data$ride_length<0),]
```

### Conduct Descriptive Analysis
```{r Descriptive Analysis}
mean(Cyclistic_Data_v2$ride_length) #straight average (total ride length / rides)
median(Cyclistic_Data_v2$ride_length) #midpoint number in the ascending array of ride lengths
max(Cyclistic_Data_v2$ride_length) #longest ride
min(Cyclistic_Data_v2$ride_length) #shortest ride
```

You can condense the four lines above to one line using summary() on the specific attribute
```{r summary}
summary(Cyclistic_Data_v2$ride_length)
```

Compare members and casual users
```{r aggregrate}
aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual, FUN = mean)
aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual, FUN = median)
aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual, FUN = max)
aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual, FUN = min)
aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual + Cyclistic_Data_v2$day_of_week, FUN = mean) # See the average ride time by each day for members vs casual user
```

Notice that the days of the week are out of order. Let's fix that.
```{r reorder}
Cyclistic_Data_v2$day_of_week <- ordered(Cyclistic_Data_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual + Cyclistic_Data_v2$day_of_week, FUN = mean) #average ride time by each day for members vs casual users
```

Analyze ridership data by type and weekday
```{r analyzing data by type and weekday}
Cyclistic_Data_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)								# sorts
```

### Visualize number of rides by rider type and average duration
```{r visualize}
Cyclistic_Data_v2 %>% 
    mutate(weekday = wday(started_at, label = TRUE)) %>%
  group_by(member_casual, weekday) %>%
  summarise(number_of_rides = n()
  ,average_duration = mean(ride_length)) %>%
  arrange(member_casual, weekday)	%>%
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
Cyclistic_Data_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```
### Exporting summary file for further analysis
```{r export}
Cyclistic_Data_Count <- aggregate(Cyclistic_Data_v2$ride_length ~ Cyclistic_Data_v2$member_casual + Cyclistic_Data_v2$day_of_week, FUN = mean)
write.csv(Cyclistic_Data_Count, file = "../avg_ride_length.csv")
write.csv(Cyclistic_Data_v2, file = "../cyclistic_cleaned_data.csv")
